from pathlib import Path
import pandas as pd
from datetime import datetime

# Pipeline metadata
pipeline_info = {
    "created_date": "2025-05-26 17:45:47",
    "created_by": "hingelman"
}

# Print pipeline info at startup
print(f"Pipeline created by {pipeline_info['created_by']} on {pipeline_info['created_date']}")

configfile: "config/config.yaml"

# Create required directories
required_dirs = [
    "raw_data/sra",
    "raw_data/fastq",
    "trimmed_data",
    "fastqc_results",
    "alignments",
    "counts",
    "logs"
]

for path in required_dirs:
    Path(path).mkdir(parents=True, exist_ok=True)

# Read sample information
samples_df = pd.read_csv(config["samples"])
SAMPLES = samples_df['Run'].tolist()

# Print debug info
print("Samples found:", SAMPLES)

# Final output files that we want to generate
rule all:
    input:
        "counts/gene_counts.txt",
        expand("alignments/{sample}.sorted.bam.bai", sample=SAMPLES)


# Build HISAT2 index
rule hisat2_index:
    input:
        fasta=lambda wildcards: next(Path(config["reference_dir"]).glob("*.fna"))
    output:
        multiext("reference/hisat2_index/genome",
                ".1.ht2", ".2.ht2", ".3.ht2", ".4.ht2",
                ".5.ht2", ".6.ht2", ".7.ht2", ".8.ht2")
    log:
        "logs/hisat2_index/build.log"
    conda:
        "envs/rnaseq.yaml"
    threads: config["threads"]["hisat2_build"]
    shell:
        "mkdir -p $(dirname {output[0]}) && "
        "hisat2-build {input.fasta} reference/hisat2_index/genome "
        "-p {threads} > {log} 2>&1"

# Sort BAM files
rule samtools_sort:
    input:
        "alignments/{sample}.unsorted.bam"
    output:
        "alignments/{sample}.sorted.bam"
    log:
        "logs/samtools_sort/{sample}.log"
    conda:
        "envs/rnaseq.yaml"
    threads: config["threads"]["samtools_sort"]
    shell:
        "samtools sort -@ {threads} "
        "-o {output} {input} > {log} 2>&1"

# Index BAM files
rule samtools_index:
    input:
        "alignments/{sample}.sorted.bam"
    output:
        "alignments/{sample}.sorted.bam.bai"
    log:
        "logs/samtools_index/{sample}.log"
    conda:
        "envs/rnaseq.yaml"
    shell:
        "samtools index {input} > {log} 2>&1"

# Count reads with featureCounts
rule featurecounts:
    input:
        bams=expand("alignments/{sample}.sorted.bam", sample=SAMPLES),
        gtf=lambda wildcards: next(Path(config["reference_dir"]).glob("*.gtf"))
    output:
        counts="counts/gene_counts.txt",
        summary="counts/gene_counts.txt.summary"
    log:
        "logs/featurecounts/counts.log"
    conda:
        "envs/rnaseq.yaml"
    threads: config["threads"]["featurecounts"]
    params:
        feature_type=config["featurecounts"]["feature_type"],
        attribute_type=config["featurecounts"]["attribute_type"],
        extra=config["featurecounts"]["extra"]
    shell:
        "featureCounts "
        "-T {threads} "
        "-t {params.feature_type} "
        "-g {params.attribute_type} "
        "{params.extra} "
        "-a {input.gtf} "
        "-o {output.counts} "
        "{input.bams} > {log} 2>&1"